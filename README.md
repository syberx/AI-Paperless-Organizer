<div align="center">

# ğŸ¤– AI Paperless Organizer

**KI-gestÃ¼tzte Metadaten-Bereinigung & OCR fÃ¼r Paperless-ngx**

[![GitHub](https://img.shields.io/badge/GitHub-syberx%2FAI--Paperless--Organizer-blue?logo=github)](https://github.com/syberx/AI-Paperless-Organizer)
[![Docker Hub](https://img.shields.io/badge/Docker%20Hub-webdienste%2Fai--paperless--organizer-blue?logo=docker)](https://hub.docker.com/r/webdienste/ai-paperless-organizer)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[![Ko-fi](https://img.shields.io/badge/Ko--fi-Support%20me-FF5E5B?logo=ko-fi&logoColor=white)](https://ko-fi.com/chriswilms)
[![PayPal](https://img.shields.io/badge/PayPal-Donate-00457C?logo=paypal&logoColor=white)](https://www.paypal.com/paypalme/withmoney)

</div>

---

## ğŸ˜« Das Problem

Kennst du das? Deine **Paperless-ngx** Installation ist Ã¼ber die Zeit gewachsen und jetzt hast du:

- **Hunderte doppelte Korrespondenten**: "Telekom", "Deutsche Telekom", "Telekom GmbH", "DTAG"...
- **UnzÃ¤hlige unsinnige Tags**: Tippfehler, Test-Tags, automatisch generierte EintrÃ¤ge von Paperless-AI oder Paperless-GPT
- **Chaos bei Dokumententypen**: "Rechnung", "Invoice", "Rechnungen", "rechnung"...

Tools wie **Paperless-AI**, **Paperless-GPT** oder einfach jahrelange Nutzung hinterlassen ein Metadaten-Chaos, das manuell kaum zu bereinigen ist.

## âœ¨ Die LÃ¶sung

**AI Paperless Organizer** analysiert deine gesamten Metadaten mit KI und schlÃ¤gt intelligente ZusammenfÃ¼hrungen vor:

<div align="center">

![Dashboard](docs/screenshots/dashboard1.png)
*Dashboard mit Statistiken und Fortschritt*

</div>

---

## ğŸ¯ Features

### ğŸ§  KI-gestÃ¼tzte Ã„hnlichkeitserkennung
Die KI findet automatisch zusammengehÃ¶rige EintrÃ¤ge - auch bei unterschiedlichen Schreibweisen, AbkÃ¼rzungen oder Tippfehlern.

<div align="center">

![Korrespondenten Analyse](docs/screenshots/korrespondentten.png)
*KI gruppiert Ã¤hnliche Korrespondenten mit Konfidenz-Werten*

</div>

### ğŸ’¾ Analyse-Ergebnisse zwischenspeichern
KI-Analysen werden gespeichert und kÃ¶nnen **kostenlos** wieder geladen werden. So kannst du die VorschlÃ¤ge in Ruhe durchgehen, ohne jedes Mal neue KI-Kosten zu verursachen.

<div align="center">

![Zwischenspeicher](docs/screenshots/zwischenspeicher.png)
*Gespeicherte Analyse laden oder neue starten*

</div>

### ğŸ§¹ Tag Cleanup Wizard
5-stufiger Assistent zur systematischen Tag-Bereinigung:

1. **Leere Tags lÃ¶schen** - Tags ohne Dokumente entfernen
2. **Unsinnige Tags** - KI identifiziert Tippfehler, Test-Tags, Fragmente
3. **Korrespondenten-Tags** - Tags die eigentlich Firmen/Personen sind
4. **Dokumententyp-Tags** - Tags die eigentlich Dokumententypen sind
5. **Ã„hnliche zusammenlegen** - Duplikate und Varianten zusammenfÃ¼hren

<div align="center">

![Tag Wizard](docs/screenshots/tag-wizzard.png)
*Tag Cleanup Wizard erkennt unsinnige Tags automatisch*

</div>

### ğŸ“ Prompts anpassen
Nicht zufrieden mit den KI-VorschlÃ¤gen? Passe die Prompts an deine BedÃ¼rfnisse an! Die KI verwendet deine individuellen Anweisungen fÃ¼r bessere Ergebnisse.

### ğŸ‘ï¸ Dokument-Vorschau
Unsicher ob zwei EintrÃ¤ge wirklich zusammengehÃ¶ren? Schau dir die zugehÃ¶rigen Dokumente direkt an, bevor du zusammenfÃ¼hrst.

### ğŸ“Š Statistiken & Fortschritt
Behalte den Ãœberblick: Wie viele EintrÃ¤ge wurden bereinigt? Wie viel Zeit gespart? Letzte AktivitÃ¤ten auf einen Blick.

### ğŸ” OCR mit Ollama Vision
Dokumente mit besserer OCR-Erkennung neu verarbeiten â€“ powered by **Ollama Vision Models**:

- **Einzel-OCR**: Dokument-ID eingeben, alten und neuen Text vergleichen, Ã¼bernehmen
- **Batch-OCR**: Alle Dokumente oder nur getaggte in einem Durchlauf verarbeiten
- **Multi-Server Failover**: Mehrere Ollama-Server konfigurieren fÃ¼r Ausfallsicherheit
- **Statistiken**: Verarbeitete Seiten, Zeichen, Dauer pro Dokument im Ãœberblick
- **Watchdog**: Automatische OCR-Verarbeitung neuer Dokumente im Hintergrund
- **Tag-basierter Workflow**: `runocr` und `ocrfinish` Tags fÃ¼r flexible Steuerung
- **Ollama-Modelle automatisch erkennen**: Dropdown in den Einstellungen statt manueller Eingabe

<div align="center">

![OCR Statistiken](docs/screenshots/ocr-stats.png)
*OCR Gesamtstatus mit Fortschritt, Statistiken und letzten AktivitÃ¤ten*

</div>

> ğŸ’¡ **Vorteil:** Deine Dokumente verlassen nie den Server â€“ Ollama lÃ¤uft lokal!

### ğŸ† OCR Modell-Vergleich & KI-Benchmark

Vergleiche verschiedene Ollama-Vision-Modelle direkt auf demselben Dokument â€“ mit detaillierter KI-QualitÃ¤tsbewertung:

<div align="center">

![OCR Modell-Vergleich](docs/ocr-benchmark/ocr-model-compare-ui.png)
*OCR Vergleichstool: Mehrere Modelle auf einem Dokument testen*

</div>

- **Bis zu 5 Modelle** gleichzeitig vergleichen (z.B. qwen3-vl:4b vs. 8b vs. glm-ocr vs. minicpm-v)
- **Seite-fÃ¼r-Seite** Ergebnisse nebeneinander mit Zeitangabe
- **Modellspezifische Prompts**: Jedes Modell bekommt den optimalen Prompt (qwen, glm-ocr, deepseek-ocr, gemma3, minicpm-v)
- **Health-Check & Auto-Recovery**: PrÃ¼ft Ollama vor jedem Modell, wartet bei Absturz

#### KI-QualitÃ¤tsbewertung

Nach dem Vergleich kann ein **Cloud-LLM** (z.B. GPT-4o, o3, GPT-4.1) die OCR-Ergebnisse bewerten:

<div align="center">

![KI-QualitÃ¤tsbewertung](docs/ocr-benchmark/ocr-ki-quality-assessment.png)
*KI-Bewertung: 10 Kategorien, Fehler-Erkennung und Modell-Empfehlung*

</div>

- **10 Bewertungskategorien**: Namen, Datum, IBAN, BetrÃ¤ge, Adressen, Formularlogik, VollstÃ¤ndigkeit, Formatierung, Halluzinierung, Automatisierbarkeit
- **Kritische Felder** mit strenger Bewertung (IBAN-Fehler = sofort kritisch)
- **Cross-Comparison**: Wo stimmen alle Modelle Ã¼berein, wo gibt es WidersprÃ¼che?
- **Strukturierte Empfehlung**: Bestes Modell fÃ¼r QualitÃ¤t, Geschwindigkeit und Preis/Leistung

#### Empfohlene OCR-Modelle

| Modell | Parameter | VRAM | StÃ¤rke |
|--------|-----------|------|--------|
| **`qwen3-vl:4b-instruct`** | 4B | ~3 GB | Bester Allrounder, zuverlÃ¤ssig bei IBANs |
| **`huihui_ai/qwen3-vl-abliterated:8b`** | 8B | ~6 GB | 8B ohne Safety-Filter (erkennt IBANs!) |
| **`glm-ocr`** | 1.1B | ~2 GB | Ultra-schnell, gut bei Standard-Dokumenten |
| **`minicpm-v`** | 8B | ~5.5 GB | Stark bei OCR-Benchmarks, Multi-Image |
| **`qwen2.5vl:7b`** | 7B | ~6 GB | BewÃ¤hrt, gute QualitÃ¤t |

> âš ï¸ **Hinweis:** Das Standard-Modell `qwen3-vl:8b-instruct` hat **Safety-Filter** von Alibaba, die sensible Felder wie IBANs filtern. FÃ¼r vollstÃ¤ndige Transkription die **abliterated-Variante** oder `4b-instruct` verwenden.

> Mehr Details & Benchmark-Infos: [docs/ocr-benchmark/](docs/ocr-benchmark/)

### ğŸ—‘ï¸ Dokumente AufrÃ¤umen
Junk-Dokumente wie AGB, Widerrufsbelehrungen und DatenschutzerklÃ¤rungen automatisch finden und entfernen:

- **Titel-basierte Suche**: Findet nur Dokumente mit typischen Junk-Titeln (keine falschen Treffer bei normalen Dokumenten)
- **Kartenansicht mit Vorschaubildern**: GroÃŸe Thumbnails fÃ¼r schnelle visuelle PrÃ¼fung
- **Mehrfachauswahl**: Einzeln oder alle auf einmal auswÃ¤hlen
- **BestÃ¤tigungsdialog**: Sicherheitsabfrage vor endgÃ¼ltiger LÃ¶schung
- **Standard-Suchbegriffe**: AGB, Widerruf, DatenschutzerklÃ¤rung, Impressum, Nutzungsbedingungen u.v.m.

---

## âš ï¸ Hinweis zum aktuellen Stand

> **Aktuell getestet:** OpenAI (GPT-4o, GPT-4o-mini)
> 
> Andere LLM-Provider (Anthropic, Ollama, Azure) sind implementiert, aber noch nicht ausfÃ¼hrlich getestet. Bei Problemen gerne ein Issue erstellen - wir verbessern kontinuierlich!

---

## ğŸ”’ Datenschutz

**Wichtig:** An das LLM werden **ausschlieÃŸlich Metadaten** Ã¼bermittelt:
- Namen von Tags, Korrespondenten und Dokumententypen
- Anzahl der zugehÃ¶rigen Dokumente

**âŒ Es werden KEINE Dokumenteninhalte, Texte oder Dateien an das LLM gesendet!**

Die KI sieht nur die Namen deiner Metadaten (z.B. "Telekom", "Rechnung", "Steuer 2024") um Ã„hnlichkeiten zu erkennen - niemals den Inhalt deiner Dokumente.

> ğŸ’¡ **Tipp:** FÃ¼r maximalen Datenschutz nutze **Ollama** mit lokalen Modellen - dann verlassen keine Daten deinen Server!

---

## ğŸš€ Quick Start

### Option 1: Docker Hub (Empfohlen)

```yaml
# docker-compose.yml
services:
  backend:
    image: webdienste/ai-paperless-organizer:backend-latest
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
    environment:
      - DATABASE_URL=sqlite+aiosqlite:///./data/organizer.db

  frontend:
    image: webdienste/ai-paperless-organizer:frontend-latest
    ports:
      - "3001:80"
    depends_on:
      - backend
```

```bash
docker-compose up -d
```

### Option 2: Selbst bauen

```bash
git clone https://github.com/syberx/AI-Paperless-Organizer.git
cd AI-Paperless-Organizer
docker-compose up -d --build
```

### ğŸŒ Ã–ffnen

**Webinterface:** http://localhost:3001

---

## âš™ï¸ Konfiguration

### 1. Paperless-ngx verbinden

1. Gehe zu **Einstellungen** â†’ Paperless-ngx
2. URL eingeben (z.B. `https://paperless.example.com`)
3. API Token aus Paperless: *Admin â†’ Auth Tokens â†’ Neuer Token*
4. **Verbindung testen**

### 2. LLM Provider einrichten

| Provider | API Key von | Empfohlenes Modell | Status |
|----------|-------------|-------------------|--------|
| **OpenAI** | [platform.openai.com](https://platform.openai.com/api-keys) | `gpt-4o` | âœ… Getestet |
| **Anthropic** | [console.anthropic.com](https://console.anthropic.com/) | `claude-3-5-sonnet` | ğŸ”„ Beta |
| **Ollama** | Kein Key nÃ¶tig! | `llama3.1` | ğŸ”„ Beta |
| **Azure** | Azure Portal | Dein Deployment | ğŸ”„ Beta |

### 3. Sensible Daten schÃ¼tzen

1. **Backend-Datenbank nie committen** â€“ dank `.gitignore` und `backend/.dockerignore` wird `backend/data/organizer.db` automatisch ausgeschlossen. Vor einem Commit kannst du mit `python scripts/sanitize_data.py` (optional `--dry-run`) alle echten SQLite-Dateien aus dem Data-Ordner entfernen.
2. **Docker-Builds bleiben sauber** â€“ der neue `backend/.dockerignore` verhindert, dass lokale Dumps in Images landen. FÃ¼r produktive Instanzen mountest du wie gehabt ein leeres Volume (`./backend/data:/app/data`).
3. **Screenshots** â€“ bleiben erhalten, aber prÃ¼fe vor VerÃ¶ffentlichung, ob keine vertraulichen Informationen zu sehen sind.

---

## ğŸ“– Empfohlener Workflow

```
1ï¸âƒ£ Korrespondenten    â†’    2ï¸âƒ£ Dokumententypen    â†’    3ï¸âƒ£ Tags
```

### FÃ¼r jeden Bereich:

1. **Leere entfernen** - Ungenutzte EintrÃ¤ge (0 Dokumente) lÃ¶schen
2. **Mit KI analysieren** - Ã„hnliche EintrÃ¤ge finden lassen
3. **VorschlÃ¤ge prÃ¼fen** - Bei Bedarf Dokumente ansehen
4. **ZusammenfÃ¼hren oder Ignorieren** - Du entscheidest!

### Tipps:
- Beginne mit **Korrespondenten** - sie sind die wichtigste Basis
- Nutze den **Tag Cleanup Wizard** fÃ¼r systematische Tag-Bereinigung
- **Gespeicherte Analysen** sparen KI-Kosten beim erneuten Ã–ffnen

---

## ğŸ—ï¸ Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Docker Compose                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Frontend (React)  â”‚           Backend (FastAPI)           â”‚
â”‚   Port: 3001        â”‚           Port: 8000                  â”‚
â”‚                     â”‚                                       â”‚
â”‚   â€¢ Dashboard       â”‚   â€¢ Paperless API Client              â”‚
â”‚   â€¢ Korrespondenten â”‚   â€¢ LLM Provider (OpenAI, etc.)       â”‚
â”‚   â€¢ Tags            â”‚   â€¢ Similarity Service                â”‚
â”‚   â€¢ Dokumententypen â”‚   â€¢ Merge Service                     â”‚
â”‚   â€¢ Tag Wizard      â”‚   â€¢ OCR Service (Ollama Vision)       â”‚
â”‚   â€¢ OCR Manager     â”‚   â€¢ Cleanup Service                   â”‚
â”‚   â€¢ AufrÃ¤umen       â”‚   â€¢ SQLite (Cache/History)            â”‚
â”‚   â€¢ Prompts         â”‚                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚               â”‚
                          â–¼               â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ Paperless   â”‚   â”‚   Ollama     â”‚
                â”‚    -ngx     â”‚   â”‚  (lokal)     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

| Bereich | Technologie |
|---------|-------------|
| **Backend** | Python 3.11, FastAPI, SQLAlchemy, httpx |
| **Frontend** | React 18, TypeScript, Vite, TailwindCSS |
| **Database** | SQLite (fÃ¼r Cache, History, Einstellungen) |
| **Container** | Docker, Docker Compose |
| **LLM** | OpenAI, Anthropic, Azure, Ollama |
| **OCR** | Ollama Vision API (qwen3-vl, glm-ocr, minicpm-v, etc.) |

---

## ğŸ¤ Beitragen

BeitrÃ¤ge sind willkommen! 

1. Fork das Repository
2. Erstelle einen Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit deine Ã„nderungen (`git commit -m 'Add AmazingFeature'`)
4. Push zum Branch (`git push origin feature/AmazingFeature`)
5. Ã–ffne einen Pull Request

### Issues willkommen fÃ¼r:
- ğŸ› Bug Reports
- ğŸ’¡ Feature Requests  
- ğŸ”Œ Andere LLM Provider testen
- ğŸŒ Ãœbersetzungen

---

## ğŸ’– UnterstÃ¼tzen

Wenn dir dieses Projekt gefÃ¤llt und Zeit spart, kannst du mich unterstÃ¼tzen:

<div align="center">

[![Ko-fi](https://img.shields.io/badge/Ko--fi-Support%20me-FF5E5B?logo=ko-fi&logoColor=white&style=for-the-badge)](https://ko-fi.com/chriswilms)
[![PayPal](https://img.shields.io/badge/PayPal-Donate-00457C?logo=paypal&logoColor=white&style=for-the-badge)](https://www.paypal.com/paypalme/withmoney)

</div>

---

## ğŸ“„ Lizenz

Dieses Projekt ist unter der MIT-Lizenz lizenziert - siehe [LICENSE](LICENSE) fÃ¼r Details.

---

<div align="center">

**Made with â¤ï¸ for the Paperless-ngx Community**

*Endlich Ordnung in deinen Metadaten!*

[â¬† Nach oben](#-ai-paperless-organizer)

</div>
